{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMcCOoXIepILDvLaCN9s4d3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MLo7Ghinsan/DiffSinger_colab_notebook_MLo7/blob/main/DDSP_Vocoder_training_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zW_ptHQW9FXh"
      },
      "outputs": [],
      "source": [
        "#@title # Mount Google Drive and Setup\n",
        "\n",
        "\n",
        "#ill put the imports here too ig\n",
        "from IPython.display import clear_output\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import yaml\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "!rm -rf /content/sample_data\n",
        "\n",
        "!git clone https://github.com/yxlllc/pc-ddsp\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -r pc-ddsp/requirements.txt\n",
        "!pip install pydub\n",
        "from pydub import AudioSegment\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Extract Data & Preprocessing\n",
        "#@markdown ___\n",
        "\n",
        "#@markdown Path to zip file containing your audio data\n",
        "data_zip_path = \"\" # @param {type:\"string\"}\n",
        "\n",
        "#@markdown Name of the folder that stuff will be saved in (or just think of speaker's name)\n",
        "folder_name = \"\" # @param {type:\"string\"}\n",
        "\n",
        "#@markdown Config type you want to use\n",
        "train_config = \"combsub\" # @param [\"combsub\", \"sins\"]\n",
        "\n",
        "#@markdown Pitch extractor algorithm\n",
        "f0_ext = \"parselmouth\" # @param [\"parselmouth\", \"dio\", \"harvest\"]\n",
        "f0_min = 12 #C0\n",
        "f0_max = 2100 #about C7\n",
        "\n",
        "#@markdown Model save interval\n",
        "interval_val = 2000 # @param {type:\"slider\", min:100, max:10000, step:100}\n",
        "\n",
        "#@markdown Model save path\n",
        "expdir = \"\" # @param {type:\"string\"}\n",
        "\n",
        "train_path = f\"{expdir}/{folder_name}/audio_data/train/audio\"\n",
        "val_path = f\"{expdir}/{folder_name}/audio_data/val/audio\"\n",
        "\n",
        "train_path_conf = f\"{expdir}/{folder_name}/audio_data/train\"\n",
        "val_path_conf = f\"{expdir}/{folder_name}/audio_data/val\"\n",
        "\n",
        "expdir_name = expdir + \"/\" + folder_name\n",
        "\n",
        "!rm -rf {expdir}/{folder_name}/* >/dev/null 2>&1\n",
        "\n",
        "if not os.path.exists(train_path):\n",
        "    os.makedirs(train_path)\n",
        "    os.makedirs(val_path)\n",
        "!7z e \"$data_zip_path\" -o{train_path} *.wav -r\n",
        "\n",
        "def get_wav_duration(wav_file):\n",
        "    audio = AudioSegment.from_file(wav_file)\n",
        "    return len(audio) / 1000\n",
        "\n",
        "wav_files = [f for f in os.listdir(train_path) if f.endswith(\".wav\")]\n",
        "\n",
        "if not wav_files: #incase there's no wav in there which i doubt that there wont be any\n",
        "    print(\"No WAV files found in the folder.\")\n",
        "else:\n",
        "    shortest_duration = float('inf')\n",
        "    for wav_file in wav_files:\n",
        "        duration = get_wav_duration(os.path.join(train_path, wav_file))\n",
        "        if duration < shortest_duration:\n",
        "            shortest_duration = duration\n",
        "    duration = min(2, shortest_duration) #use this for the config later\n",
        "\n",
        "#@markdown Amount of validation files you want to use (can't exceed the amount of train files)\n",
        "val_amount = 8 # @param {type:\"slider\", min:1, max:18, step:1}\n",
        "\n",
        "all_shits = os.listdir(train_path)\n",
        "random.shuffle(all_shits)\n",
        "\n",
        "val_files = all_shits[:val_amount]\n",
        "\n",
        "for rats in val_files:\n",
        "    og = os.path.join(train_path, rats)\n",
        "    dest = os.path.join(val_path, rats)\n",
        "    shutil.copy2(og, dest)\n",
        "print(\"\\n\")\n",
        "print(f\"using {val_files} as validation files\")\n",
        "\n",
        "with open(f\"/content/pc-ddsp/configs/{train_config}.yaml\", \"r\") as config:\n",
        "    ew = yaml.safe_load(config)\n",
        "ew[\"data\"][\"f0_extractor\"] = f0_ext\n",
        "ew[\"data\"][\"f0_min\"] = f0_min\n",
        "ew[\"data\"][\"f0_max\"] = f0_max\n",
        "ew[\"data\"][\"duration\"] = duration\n",
        "ew[\"data\"][\"train_path\"] = train_path_conf\n",
        "ew[\"data\"][\"valid_path\"] = val_path_conf\n",
        "ew[\"train\"][\"interval_val\"] = interval_val\n",
        "ew[\"env\"][\"expdir\"] = expdir_name\n",
        "with open(f\"/content/pc-ddsp/configs/{train_config}.yaml\", \"w\") as config:\n",
        "    yaml.dump(ew, config)\n",
        "print(\"\\n\")\n",
        "\n",
        "!python /content/pc-ddsp/preprocess.py -c /content/pc-ddsp/configs/{train_config}.yaml"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WjKHanCFErik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Tensorboard\n",
        "#@markdown ___\n",
        "\n",
        "#@markdown path to your save dir basically\n",
        "logdir = \"\" # @param {type:\"string\"}\n",
        "!tensorboard --logdir={logdir}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JH_UodJ0QWYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Training\n",
        "#@markdown ___\n",
        "\n",
        "#@markdown Only check this if you want to resume training\n",
        "resume_training = False # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Path to the config you want to resume\n",
        "re_config = \"\" # @param {type:\"string\"}\n",
        "\n",
        "if resume_training:\n",
        "    !python /content/pc-ddsp/train.py -c {re_config}\n",
        "else:\n",
        "    !python /content/pc-ddsp/train.py -c /content/pc-ddsp/configs/{train_config}.yaml"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DNygi3C5RbtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Export your model\n",
        "#@markdown ___\n",
        "#@markdown Path to your vocoder model\n",
        "\n",
        "pt_path = \"\" # @param {type:\"string\"}\n",
        "\n",
        "!python /content/pc-ddsp/export.py -m {pt_path} --traced"
      ],
      "metadata": {
        "cellView": "form",
        "id": "bdM5cvv_CD41"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}