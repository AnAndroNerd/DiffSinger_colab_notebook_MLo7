{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "MP5rRkbTpnG8",
        "Wv0gfI5feBSc",
        "eexZl_OCDmQ3",
        "0J3b18EKdzMC",
        "FY40fGHEg9_i",
        "4sbU1aH5kGFE"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MLo7Ghinsan/DiffSinger_colab_notebook_MLo7/blob/main/DiffSinger_colab_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP5rRkbTpnG8"
      },
      "source": [
        "# _**[DiffSinger](https://github.com/openvpi/DiffSinger)**_\n",
        "_Singing Voice Synthesis via Shallow Diffusion Mechanism (SVS & TTS)_\n",
        "\n",
        "____\n",
        "\n",
        "Note:\n",
        "- This notebook will get update semi-frequently based from the feedback or response from users\n",
        "\n",
        "\\\n",
        "____\n",
        "\\\n",
        "#### **This notebook is an edited copy of Kei's Diffsinger [colab notebook](https://colab.research.google.com/drive/1kUg9dz8PPH92NfnLZwgq0_9B9an39t1J?usp=sharing)**\n",
        "####**This notebook is maintained by MLo7**\n",
        "\\\n",
        "___\n",
        "\n",
        "```Expand this cell for more details```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### IMPORTANT NOTE:\n",
        "\n",
        "- your_speaker_folder's folder name will be used as *spk_name* so please be careful about your file naming\n",
        "- colab notebook primarily uses python; thus space in file name or folder path may be invalid\n",
        "- for an in-depth guide for SVS training and/or labeling, please see [SVS Singing Voice Database - Tutorial](https://docs.google.com/document/d/1uMsepxbdUW65PfIWL1pt2OM6ZKa5ybTTJOpZ733Ht6s/edit?usp=sharing)"
      ],
      "metadata": {
        "id": "pMdzk_3sjD81"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook converts your data (lab + wav) to compatible format via [nnsvs-db-converter](https://github.com/UtaUtaUtau/nnsvs-db-converter)\n",
        "\n",
        "It is advised to edit your data using [SlurCutter](https://github.com/openvpi/MakeDiffSinger/releases) for a more refined data for your pitch model\n",
        "\n",
        "Zip file format [example](https://github.com/MLo7Ghinsan/DiffSinger_colab_notebook_MLo7/releases/tag/ref):\n",
        "<pre>\n",
        "#single speaker (lab + wav | ds + wav)\n",
        "your_zip.zip:\n",
        "    |\n",
        "    |\n",
        "    your_speaker_folder:\n",
        "        |\n",
        "        |\n",
        "        data_1.wav\n",
        "        data_1.lab (or.ds)\n",
        "        .\n",
        "        data_2.wav\n",
        "        data_2.lab (or.ds)\n",
        "        .\n",
        "        data_3.wav\n",
        "        data_3.lab (or.ds)\n",
        "        .\n",
        "        ...\n",
        "</pre>\n",
        "<pre>\n",
        "#single speaker (csv + wav)\n",
        "your_zip.zip:\n",
        "    |\n",
        "    |\n",
        "    your_speaker_folder:\n",
        "        |\n",
        "        |\n",
        "        wavs (folder named \"wavs\" containing all the wavs)\n",
        "        .\n",
        "        transcriptions.csv\n",
        "</pre>\n",
        "<pre>\n",
        "#multi speaker (lab + wav | ds + wav)\n",
        "your_zip.zip:\n",
        "    |\n",
        "    |\n",
        "    your_speaker_folder_1:\n",
        "        |\n",
        "        |\n",
        "        data_1.wav\n",
        "        data_1.lab (or.ds)\n",
        "        .\n",
        "        data_2.wav\n",
        "        data_2.lab (or.ds)\n",
        "        .\n",
        "        data_3.wav\n",
        "        data_3.lab (or.ds)\n",
        "        .\n",
        "        ...\n",
        "    your_speaker_folder_2:\n",
        "        |\n",
        "        |\n",
        "        data_1.wav\n",
        "        data_1.lab (or.ds)\n",
        "        .\n",
        "        data_2.wav\n",
        "        data_2.lab (or.ds)\n",
        "        .\n",
        "        data_3.wav\n",
        "        data_3.lab (or.ds)\n",
        "        .\n",
        "        ...\n",
        "</pre>\n",
        "<pre>\n",
        "#multi speaker (csv + wav)\n",
        "your_zip.zip:\n",
        "    |\n",
        "    |\n",
        "    your_speaker_folder_1:\n",
        "        |\n",
        "        |\n",
        "        wavs (folder named \"wavs\" containing all the wavs)\n",
        "        .\n",
        "        transcriptions.csv\n",
        "    your_speaker_folder_2:\n",
        "        |\n",
        "        |\n",
        "        wavs (folder named \"wavs\" containing all the wavs)\n",
        "        .\n",
        "        transcriptions.csv\n",
        "\n",
        "</pre>"
      ],
      "metadata": {
        "id": "ZxsTaNBJLd7Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "_**Credits:** _\n",
        "\n",
        "  - [openvpi](https://openvpi.github.io/) for DiffSinger fork and more\n",
        "\n",
        "  - [UtaUtaUtau](https://utautautau.neocities.org/) for nnsvs-db-converter\n",
        "\n",
        "  - [Kei](https://pronouns.page/@kei.wendt06) for the original notebook\n",
        "\n",
        "  - [MLo7](https://github.com/MLo7Ghinsan) for the notebook edit\n",
        "\n",
        "  - [PixPrucer](https://twitter.com/PixPrucer?s=20) for an in-depth SVS guide"
      ],
      "metadata": {
        "id": "R8o4pZptA4yc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Setup**"
      ],
      "metadata": {
        "id": "Wv0gfI5feBSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Select this if you don't like seeing warnings throughout your training since most of the time the warnings are nothing to worry about\n",
        "\n",
        "#@markdown ****WARNING**** this will also hides the error message\n",
        "no_warn = False # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown <font size=\"-1.5\"> you can always come back and enable or disable this cell without re-running the installation"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9nZnrUAVHPZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pK8aicf8A2sj"
      },
      "outputs": [],
      "source": [
        "#@title # Mount Google Drive and Setup\n",
        "\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import Audio, display, HTML\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "if not os.path.exists(\"/content/play_sound\"):\n",
        "    os.makedirs(\"/content/play_sound\")\n",
        "%cd /content/play_sound\n",
        "!wget -O setup_complete.wav https://github.com/MLo7Ghinsan/MLo7_Diff-SVC_models/releases/download/audio/setup_complete.wav\n",
        "%cd /content\n",
        "!rm -rf /content/sample_data\n",
        "!apt-get install aria2\n",
        "clear_output()\n",
        "\n",
        "!git clone https://github.com/UtaUtaUtau/nnsvs-db-converter\n",
        "!git clone https://github.com/openvpi/DiffSinger.git --branch v2.1.0\n",
        "\n",
        "clear_output()\n",
        "!pip install torch==1.13.0 torchvision==0.14.0 torchaudio==0.13.0\n",
        "clear_output()\n",
        "!pip install -r /content/DiffSinger/requirements.txt\n",
        "clear_output()\n",
        "!aria2c https://github.com/openvpi/vocoders/releases/download/nsf-hifigan-v1/nsf_hifigan_20221211.zip\n",
        "!aria2c https://github.com/openvpi/DiffSinger/releases/download/v2.1.0/rmvpe.zip\n",
        "!unzip -q /content/nsf_hifigan_20221211.zip -d /content/DiffSinger/checkpoints\n",
        "!unzip -q /content/rmvpe.zip -d /content/DiffSinger/checkpoints\n",
        "!unzip -q /content/rmvpe.zip -d /content/MakeDiffSinger/variance-temp-solution/assets\n",
        "!rm /content/nsf_hifigan_20221211.zip\n",
        "!rm /content/rmvpe.zip\n",
        "clear_output()\n",
        "!pip install --upgrade tensorboard\n",
        "clear_output()\n",
        "!pip install protobuf #protobuf==3.20\n",
        "clear_output()\n",
        "!pip install onnxruntime\n",
        "clear_output()\n",
        "#shit tons of clear output cus i dont wanna see anything <3\n",
        "\n",
        "print(\"setup complete!\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "\n",
        "chika_dance = '<img src=\"https://cdn.discordapp.com/attachments/816517150175920138/1090112497446563950/icegif-2013.gif\"/>'\n",
        "display(HTML(chika_dance))\n",
        "\n",
        "with open(\"/content/play_sound/setup_complete.wav\", \"rb\") as f:\n",
        "    setup_complete_sound = f.read()\n",
        "Audio(data=setup_complete_sound, autoplay=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocess data for training**"
      ],
      "metadata": {
        "id": "eexZl_OCDmQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Extract Data\n",
        "#@markdown ___\n",
        "%cd /content\n",
        "#@markdown this cell will create a folder name [raw_data] in the root folder and extract your data into it\n",
        "\n",
        "#@markdown <font size=\"-1.5\"> See [data type zip format](https://colab.research.google.com/github/MLo7Ghinsan/DiffSinger_colab_notebook_MLo7/blob/main/DiffSinger_colab_notebook.ipynb#scrollTo=ZxsTaNBJLd7Y) for examples (drop down the introduction cell)\n",
        "\n",
        "data_type = \"lab + wav (NNSVS format)\" # @param [\"lab + wav (NNSVS format)\", \"csv + wav (DiffSinger format)\", \"ds + wav (DiffSinger format)\"]\n",
        "\n",
        "#@markdown <font size=\"-1.5\"> The path to your data zip file\n",
        "\n",
        "data_zip_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ___\n",
        "\n",
        "#@markdown this lower section is for variance training (lab + wav ONLY)\n",
        "\n",
        "#@markdown <font size=\"-1.5\"> Use this if you don't have .cvs that is for variance dataset (skippable if you are doing acoustic)\n",
        "\n",
        "estimate_midi = False # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "all_shits = \"/content/raw_data\"\n",
        "all_shits_not_wav_n_lab = \"/content/raw_data/diffsinger_db\"\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import csv\n",
        "import json\n",
        "\n",
        "if not os.path.exists(all_shits_not_wav_n_lab):\n",
        "  os.makedirs(all_shits_not_wav_n_lab)\n",
        "\n",
        "# using 'if not' bc i edited the wrong section which im also too lazy to fix it <3\n",
        "if not data_type == \"lab + wav (NNSVS format)\":\n",
        "    #changed back to !unzip\n",
        "    !unzip {data_zip_path} -d {all_shits_not_wav_n_lab}\n",
        "    clear_output()\n",
        "else:\n",
        "    !unzip {data_zip_path} -d {all_shits_not_wav_n_lab}\n",
        "    for root, dirs, files in os.walk(all_shits):\n",
        "        for filename in files:\n",
        "            if filename.endswith(\".lab\"):\n",
        "                file_path = os.path.join(root, filename)\n",
        "                with open(file_path, \"r\") as file:\n",
        "                    file_data = file.read()\n",
        "                file_data = file_data.replace(\"SP\", \"pau\")\n",
        "                file_data = file_data.replace(\"br\", \"AP\")\n",
        "                with open(file_path, \"w\") as file:\n",
        "                    file.write(file_data)\n",
        "\n",
        "# for funny auto dict generator lmao\n",
        "out = \"/content/DiffSinger/dictionaries/custom_dict.txt\"\n",
        "\n",
        "phonemes = set()\n",
        "\n",
        "def is_excluded(phoneme):\n",
        "    return phoneme in [\"pau\", \"AP\", \"SP\"]\n",
        "\n",
        "if data_type == \"lab + wav (NNSVS format)\":\n",
        "    phoneme_folder_path = all_shits\n",
        "    for root, dirs, files in os.walk(phoneme_folder_path):\n",
        "        for file in files:\n",
        "            if file.endswith(\".lab\"):\n",
        "                fpath = os.path.join(root, file)\n",
        "                with open(fpath, \"r\") as lab_file:\n",
        "                    for line in lab_file:\n",
        "                        line = line.strip()\n",
        "                        if line:\n",
        "                            phoneme = line.split()[2]\n",
        "                            if not is_excluded(phoneme):\n",
        "                                phonemes.add(phoneme)\n",
        "elif data_type == \"csv + wav (DiffSinger format)\":\n",
        "    phoneme_folder_path = all_shits_not_wav_n_lab\n",
        "    for root, dirs, files in os.walk(phoneme_folder_path):\n",
        "        for file in files:\n",
        "            if file.endswith(\".csv\"):\n",
        "                fpath = os.path.join(root, file)\n",
        "                with open(fpath, \"r\", newline=\"\") as csv_file:\n",
        "                    csv_reader = csv.DictReader(csv_file)\n",
        "                    for row in csv_reader:\n",
        "                        if \"ph_seq\" in row:\n",
        "                            ph_seq = row[\"ph_seq\"].strip()\n",
        "                            for phoneme in ph_seq.split():\n",
        "                                if not is_excluded(phoneme):\n",
        "                                    phonemes.add(phoneme)\n",
        "else:\n",
        "    phoneme_folder_path = all_shits\n",
        "    for root, dirs, files in os.walk(phoneme_folder_path):\n",
        "        for file in files:\n",
        "            if file.endswith(\".json\"):\n",
        "                fpath = os.path.join(root, file)\n",
        "                with open(fpath, \"r\") as json_file:\n",
        "                    row = json.load(json_file)\n",
        "                    ph_seq = row[\"ph_seq\"]\n",
        "                    for phoneme in ph_seq.split():\n",
        "                        if not is_excluded(phoneme):\n",
        "                            phonemes.add(phoneme)\n",
        "\n",
        "with open(out, \"w\") as f:\n",
        "    for phoneme in sorted(phonemes):\n",
        "        f.write(phoneme + \"\t\" + phoneme + \"\\n\")\n",
        "\n",
        "# for vowels and consonants.txt.... well adding luquid type for uta's script\n",
        "dict_path = out\n",
        "vowel_types = {\"a\", \"i\", \"u\", \"e\", \"o\", \"N\", \"M\", \"NG\"}\n",
        "liquid_types = {\"y\", \"w\", \"n\", \"m\", \"ng\", \"l\", \"r\"} # r for english labels, it should be fine with jp too\n",
        "vowel_data = []\n",
        "consonant_data = []\n",
        "liquid_data = []\n",
        "\n",
        "with open(dict_path, \"r\") as f:\n",
        "    for line in f:\n",
        "        phoneme, _ = line.strip().split(\"\\t\")\n",
        "        if phoneme[0] in vowel_types:\n",
        "            vowel_data.append(phoneme)\n",
        "        elif phoneme[0] in liquid_types:\n",
        "            liquid_data.append(phoneme)\n",
        "        else:\n",
        "            consonant_data.append(phoneme)\n",
        "\n",
        "vowel_data.sort()\n",
        "liquid_data.sort()\n",
        "consonant_data.sort()\n",
        "directory = os.path.dirname(dict_path)\n",
        "\n",
        "# make txt for language json file\n",
        "vowel_txt_path = os.path.join(directory, \"vowels.txt\")\n",
        "with open(vowel_txt_path, \"w\") as f:\n",
        "    f.write(\" \".join(vowel_data))\n",
        "liquid_txt_path = os.path.join(directory, \"liquids.txt\")\n",
        "with open(liquid_txt_path, \"w\") as f:\n",
        "    f.write(\" \".join(liquid_data))\n",
        "consonant_txt_path = os.path.join(directory, \"consonants.txt\")\n",
        "with open(consonant_txt_path, \"w\") as f:\n",
        "    f.write(\" \".join(consonant_data))\n",
        "\n",
        "\n",
        "# here's a funny json append\n",
        "with open(vowel_txt_path, \"r\") as f:\n",
        "    vowel_data = f.read().split()\n",
        "with open(liquid_txt_path, \"r\") as f:\n",
        "    liquid_data = f.read().split()\n",
        "with open(consonant_txt_path, \"r\") as f:\n",
        "    consonant_data = f.read().split()\n",
        "phones4json = {\"vowels\": vowel_data, \"liquids\": liquid_data}\n",
        "with open(\"/content/nnsvs-db-converter/lang.sample.json\", \"w\") as rawr:\n",
        "    json.dump(phones4json, rawr, indent=4)\n",
        "\n",
        "\n",
        "if data_type == \"lab + wav (NNSVS format)\":\n",
        "    db_converter_script = \"/content/nnsvs-db-converter/db_converter.py\"\n",
        "    for raw_folder_name in os.listdir(all_shits_not_wav_n_lab):\n",
        "        raw_folder_path = os.path.join(all_shits_not_wav_n_lab, raw_folder_name)\n",
        "        if os.path.isdir(raw_folder_path):\n",
        "            if estimate_midi:\n",
        "                !python {db_converter_script} -s 50 -S 20 -l 30 -m -c -L \"/content/nnsvs-db-converter/lang.sample.json\" --folder {raw_folder_path} 2> /dev/null\n",
        "\n",
        "            else:\n",
        "                #!python {db_converter_script} -s 2 --folder {raw_folder_path} 2> /dev/null\n",
        "                !python {db_converter_script} -s 50 -S 20 -l 30 -L \"/content/nnsvs-db-converter/lang.sample.json\" --folder {raw_folder_path} 2> /dev/null\n",
        "    clear_output()\n",
        "else:\n",
        "    pass\n",
        "\n",
        "for raw_folder_name in os.listdir(all_shits_not_wav_n_lab):\n",
        "    raw_folder_path = os.path.join(all_shits_not_wav_n_lab, raw_folder_name)\n",
        "    !rm -rf {raw_folder_path}/*.wav {raw_folder_path}/*.lab\n",
        "    !mv {raw_folder_path}/diffsinger_db/* {raw_folder_path} 2> /dev/null\n",
        "    !rm -rf {raw_folder_path}/diffsinger_db\n",
        "    #!cp {raw_folder_path}/wavs/*.wav {raw_folder_path}\n",
        "\n",
        "print(\"extraction complete!\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"I'm also nice enough to convert your data and also write your dict.txt lmao. You are welcome :)\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JsP1TGg2F1g3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Edit Config\n",
        "#@markdown ___\n",
        "\n",
        "import os\n",
        "import yaml\n",
        "import random #for the random test files lmaoz\n",
        "\n",
        "%cd /content\n",
        "clear_output()\n",
        "#@markdown <font size=\"-1.5\"> The training type you want to do\n",
        "config_type = \"variance\" # @param [\"acoustic\", \"variance\"]\n",
        "config_cap = config_type.upper()\n",
        "\n",
        "spk_name = [folder_name for folder_name in os.listdir(all_shits_not_wav_n_lab) if os.path.isdir(os.path.join(all_shits_not_wav_n_lab, folder_name))]\n",
        "# i used spk_name for something else cus i forgor now imma just copy and paste it\n",
        "spk_names = [folder_name for folder_name in os.listdir(all_shits_not_wav_n_lab) if os.path.isdir(os.path.join(all_shits_not_wav_n_lab, folder_name))]\n",
        "num_spk = len(spk_name)\n",
        "raw_dir = []\n",
        "for folder_name in spk_name:\n",
        "    folder_path = os.path.join(all_shits_not_wav_n_lab, folder_name)\n",
        "    raw_dir.append(folder_path)\n",
        "if num_spk == 1:\n",
        "    singer_type = \"SINGLE-SPEAKER\"\n",
        "    diff_loss_type = \"l2\"\n",
        "    f0_emb = \"continuous\"\n",
        "    use_spk_id = False\n",
        "    all_wav_files = []\n",
        "    for root, dirs, files in os.walk(\"/content/raw_data/diffsinger_db\"):\n",
        "        for file in files:\n",
        "            if file.endswith(\".wav\"):\n",
        "                full_path = os.path.join(root, file)\n",
        "                all_wav_files.append(full_path)\n",
        "    random.shuffle(all_wav_files)\n",
        "    random_ass_wavs = all_wav_files[:3]\n",
        "    random_ass_test_files = [os.path.splitext(os.path.basename(file))[0] for file in random_ass_wavs]\n",
        "\n",
        "else:\n",
        "    singer_type = \"MULTI-SPEAKER\"\n",
        "    diff_loss_type = \"l1\"\n",
        "    f0_emb = \"discrete\"\n",
        "    use_spk_id = True\n",
        "    folder_to_id = {folder_name: i for i, folder_name in enumerate(spk_name)}\n",
        "    random_ass_test_files = []\n",
        "    for folder_path in raw_dir:\n",
        "        audio_files = [f[:-4] for f in os.listdir(folder_path + \"/wavs\") if f.endswith(\".wav\")]\n",
        "        folder_name = os.path.basename(folder_path)\n",
        "        folder_id = folder_to_id.get(folder_name, -1)\n",
        "        prefixed_audio_files = [f\"{folder_id}:{audio_file}\" for audio_file in audio_files]\n",
        "        random_ass_test_files.extend(prefixed_audio_files[:3])\n",
        "spk_id = []\n",
        "for i, spk_name in enumerate(spk_name):\n",
        "    spk_id_format = f\"{i}:{spk_name}\"\n",
        "    spk_id.append(spk_id_format)\n",
        "\n",
        "#@markdown <font size=\"-1.5\"> Path to where you want to save your binary data for later use\n",
        "binary_save_dir = \"t1\" #@param{type:\"string\"}\n",
        "\n",
        "#@markdown <font size=\"-1.5\"> Pitch extractor algorithm\n",
        "\n",
        "f0_ext = \"parselmouth\" # @param [\"parselmouth\", \"rmvpe\"]\n",
        "if f0_ext == \"rmvpe\":\n",
        "    pe_ckpt_pth = \"checkpoints/rmvpe/model.pt\"\n",
        "else:\n",
        "    pe_ckpt_pth = None\n",
        "\n",
        "#@markdown <font size=\"-1.5\"> Select this is you want to use data augmentation (default pitch shift and time stretch values)\n",
        "data_aug = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown <font size=\"-1.5\"> Step interval of when your model will be validate and save\n",
        "save_interval = 100 #@param {type:\"slider\", min:100, max:10000, step:100}\n",
        "\n",
        "#@markdown <font size=\"-1.5\"> Your model save path\n",
        "save_dir = \"t2\" #@param{type:\"string\"}\n",
        "\n",
        "if config_type == \"acoustic\":\n",
        "    with open(\"/content/DiffSinger/configs/acoustic.yaml\", \"r\") as config:\n",
        "        bitch_ass_config = yaml.safe_load(config)\n",
        "    bitch_ass_config[\"speakers\"] = spk_names\n",
        "    bitch_ass_config[\"test_prefixes\"] = random_ass_test_files\n",
        "    bitch_ass_config[\"raw_data_dir\"] = raw_dir\n",
        "    bitch_ass_config[\"num_spk\"] = num_spk\n",
        "    bitch_ass_config[\"use_spk_id\"] = use_spk_id\n",
        "    #bitch_ass_config[\"spk_ids\"] = spk_id\n",
        "    bitch_ass_config[\"diff_loss_type\"] = diff_loss_type\n",
        "    bitch_ass_config[\"f0_embed_type\"] = f0_emb\n",
        "    bitch_ass_config[\"binary_data_dir\"] = binary_save_dir\n",
        "    bitch_ass_config[\"dictionary\"] = \"dictionaries/custom_dict.txt\"\n",
        "    bitch_ass_config[\"augmentation_args\"][\"random_pitch_shifting\"][\"enabled\"] = data_aug\n",
        "    bitch_ass_config[\"augmentation_args\"][\"random_time_stretching\"][\"enabled\"] = data_aug\n",
        "    bitch_ass_config[\"use_key_shift_embed\"] = data_aug\n",
        "    bitch_ass_config[\"use_speed_embed\"] = data_aug\n",
        "    bitch_ass_config[\"max_batch_size\"] = 9 #ive never tried reaching the limit so ill trust kei's setting for this\n",
        "    bitch_ass_config[\"val_check_interval\"] = save_interval\n",
        "    bitch_ass_config[\"pe\"] = f0_ext\n",
        "    bitch_ass_config[\"pe_ckpt\"] = pe_ckpt_pth\n",
        "    with open(\"/content/DiffSinger/configs/acoustic.yaml\", \"w\") as config:\n",
        "        yaml.dump(bitch_ass_config, config)\n",
        "else:\n",
        "    with open(\"/content/DiffSinger/configs/variance.yaml\", \"r\") as config:\n",
        "        bitch_ass_config = yaml.safe_load(config)\n",
        "    bitch_ass_config[\"speakers\"] = spk_names\n",
        "    bitch_ass_config[\"test_prefixes\"] = random_ass_test_files\n",
        "    bitch_ass_config[\"raw_data_dir\"] = raw_dir\n",
        "    bitch_ass_config[\"num_spk\"] = num_spk\n",
        "    bitch_ass_config[\"use_spk_id\"] = use_spk_id\n",
        "    bitch_ass_config[\"diff_loss_type\"] = diff_loss_type\n",
        "    bitch_ass_config[\"binary_data_dir\"] = binary_save_dir\n",
        "    bitch_ass_config[\"dictionary\"] = \"dictionaries/custom_dict.txt\"\n",
        "    bitch_ass_config[\"max_batch_size\"] = 9 #ive never tried reaching the limit so ill trust kei's setting for this\n",
        "    bitch_ass_config[\"val_check_interval\"] = save_interval\n",
        "    bitch_ass_config[\"pe\"] = f0_ext # i think variance uses it for pitch ref as ground-truth for pitch training soooo\n",
        "    bitch_ass_config[\"pe_ckpt\"] = pe_ckpt_pth #same goes to this one\n",
        "    with open(\"/content/DiffSinger/configs/variance.yaml\", \"w\") as config:\n",
        "        yaml.dump(bitch_ass_config, config)\n",
        "\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "search_text = \"        args_work_dir = os.path.join(\"\n",
        "replacement = f\"        args_work_dir = '{save_dir}'\"\n",
        "with open(\"/content/DiffSinger/utils/hparams.py\", \"r\") as file:\n",
        "    lines = file.readlines()\n",
        "for i, line in enumerate(lines):\n",
        "    if search_text in line:\n",
        "        lines[i] = replacement + \"\\n\"\n",
        "        break\n",
        "with open(\"/content/DiffSinger/utils/hparams.py\", \"w\") as file:\n",
        "        file.writelines(lines)\n",
        "#incase if anyone wanna change it lmao\n",
        "search_text_alt = \"        args_work_dir = '\"\n",
        "replacement_alt = f\"        args_work_dir = '{save_dir}'\"\n",
        "with open(\"/content/DiffSinger/utils/hparams.py\", \"r\") as file:\n",
        "    lines = file.readlines()\n",
        "for i, line in enumerate(lines):\n",
        "    if search_text_alt in line:\n",
        "        lines[i] = replacement_alt + \"\\n\"\n",
        "        break\n",
        "with open(\"/content/DiffSinger/utils/hparams.py\", \"w\") as file:\n",
        "        file.writelines(lines)\n",
        "\n",
        "relative_p = \"            relative_path = filepath.relative_to(Path('.').resolve())\"\n",
        "relative_change = \"            relative_path = filepath.relative_to(Path('/content').resolve())\"\n",
        "with open(\"/content/DiffSinger/utils/training_utils.py\", \"r\") as file:\n",
        "    lines = file.readlines()\n",
        "for i, line in enumerate(lines):\n",
        "    if relative_p in line:\n",
        "        lines[i] = relative_change + \"\\n\"\n",
        "        break\n",
        "with open(\"/content/DiffSinger/utils/training_utils.py\", \"w\") as file:\n",
        "        file.writelines(lines)\n",
        "relative_p_2 = \"        relative_path = filepath.relative_to(Path('.').resolve())\"\n",
        "relative_change_2 = \"        relative_path = filepath.relative_to(Path('/content').resolve())\"\n",
        "with open(\"/content/DiffSinger/utils/training_utils.py\", \"r\") as file:\n",
        "    lines_2 = file.readlines()\n",
        "for i, line in enumerate(lines):\n",
        "    if relative_p_2 in line:\n",
        "        lines_2[i] = relative_change_2 + \"\\n\"\n",
        "        break\n",
        "with open(\"/content/DiffSinger/utils/training_utils.py\", \"w\") as file:\n",
        "        file.writelines(lines_2)\n",
        "\n",
        "if not estimate_midi:\n",
        "    !python /content/DiffSinger/scripts/migrate.py txt /content/raw_data/diffsinger_db/transcriptions.txt 2> /dev/null\n",
        "else:\n",
        "  pass\n",
        "\n",
        "print(\"config updated! see below for config's information\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(f\"+++---{config_cap} {singer_type} TRAINING---+++\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"|\")\n",
        "print(\"+++---user's settings---+++\")\n",
        "print(\"\\n\")\n",
        "print(f\"speaker name: {spk_names}\")\n",
        "print(\"\\n\")\n",
        "print(f\"data augmentation: {data_aug}\")\n",
        "print(\"\\n\")\n",
        "print(f\"pitch extractor: {f0_ext}\")\n",
        "print(\"\\n\")\n",
        "print(f\"binary data save directory: {binary_save_dir}\")\n",
        "print(\"\\n\")\n",
        "print(f\"your model will be saved every: {save_interval} steps\")\n",
        "print(\"\\n\")\n",
        "print(f\"your model will be saved to: {save_dir}\")\n",
        "print(\"\\n\")\n",
        "print(\"==========================================================================================\")\n",
        "print(\"\\n\")\n",
        "print(\"+++---other auto-defined settings---+++\")\n",
        "print(\"\\n\")\n",
        "print(f\"test files (auto selected): {random_ass_test_files}\")\n",
        "print(\"\\n\")\n",
        "print(\"dictionary (auto generated): custom_dict.txt\")\n",
        "print(\"\\n\")\n",
        "print(\"max_sentences: 9\")\n",
        "print(\"\\n\")\n",
        "print(\"==========================================================================================\")\n",
        "print(\"\\n\")\n",
        "print(\"if you don't like or disagree with any of these options,\")\n",
        "print(f\"you can go and edit the config at [/content/DiffSinger/configs/{config_type}.yaml]\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nI3dzDv_Mr9Y",
        "outputId": "73436fc2-a259-4111-d939-47b85b19ec10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config updated! see below for config's information\n",
            "|\n",
            "|\n",
            "|\n",
            "+++---VARIANCE SINGLE-SPEAKER TRAINING---+++\n",
            "|\n",
            "|\n",
            "|\n",
            "+++---user's settings---+++\n",
            "\n",
            "\n",
            "speaker name: ['pj_dat']\n",
            "\n",
            "\n",
            "data augmentation: False\n",
            "\n",
            "\n",
            "pitch extractor: parselmouth\n",
            "\n",
            "\n",
            "binary data save directory: t1\n",
            "\n",
            "\n",
            "your model will be saved every: 100 steps\n",
            "\n",
            "\n",
            "your model will be saved to: t2\n",
            "\n",
            "\n",
            "==========================================================================================\n",
            "\n",
            "\n",
            "+++---other auto-defined settings---+++\n",
            "\n",
            "\n",
            "test files (auto selected): ['pjs001_speech_seg000', 'pjs001_singing_seg000']\n",
            "\n",
            "\n",
            "dictionary (auto generated): custom_dict.txt\n",
            "\n",
            "\n",
            "max_sentences: 9\n",
            "\n",
            "\n",
            "==========================================================================================\n",
            "\n",
            "\n",
            "if you don't like or disagree with any of these options,\n",
            "you can go and edit the config at [/content/DiffSinger/configs/variance.yaml]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Preprocess data\n",
        "import os\n",
        "\n",
        "# idk i just feel like 800 is a lil low for some people part 2\n",
        "new_f0_max = 1600\n",
        "og_script = \"/content/DiffSinger/utils/binarizer_utils.py\"\n",
        "with open(og_script, 'r') as file:\n",
        "    mate = file.read()\n",
        "up_f0_val = mate.replace(\"f0_max = 800\", f\"f0_max = {new_f0_max}\")\n",
        "with open(og_script, 'w') as file:\n",
        "    file.write(up_f0_val)\n",
        "\n",
        "training_config = f\"/content/DiffSinger/configs/{config_type}.yaml\"\n",
        "\n",
        "%cd /content/DiffSinger\n",
        "os.environ['PYTHONPATH']='.'\n",
        "if no_warn:\n",
        "    !CUDA_VISIBLE_DEVICES=0 python /content/DiffSinger/scripts/binarize.py --config {training_config} 2> /dev/null\n",
        "else:\n",
        "    !CUDA_VISIBLE_DEVICES=0 python /content/DiffSinger/scripts/binarize.py --config {training_config}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "76NvDR1cXlDM",
        "outputId": "9e7f1cfa-5a2d-48f8-aa74-3c003252f8dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DiffSinger\n",
            "| Hparams chains:  ['configs/base.yaml', '/content/DiffSinger/configs/variance.yaml']\n",
            "| Hparams: \n",
            "\u001b[0;33mK_step\u001b[0m: 1000, \u001b[0;33maccumulate_grad_batches\u001b[0m: 1, \u001b[0;33maudio_num_mel_bins\u001b[0m: 128, \u001b[0;33maudio_sample_rate\u001b[0m: 44100, \u001b[0;33mbase_config\u001b[0m: ['configs/base.yaml'], \n",
            "\u001b[0;33mbinarization_args\u001b[0m: {'shuffle': True, 'num_workers': 0, 'prefer_ds': False}, \u001b[0;33mbinarizer_cls\u001b[0m: preprocessing.variance_binarizer.VarianceBinarizer, \u001b[0;33mbinary_data_dir\u001b[0m: t1, \u001b[0;33mbreathiness_db_max\u001b[0m: -20.0, \u001b[0;33mbreathiness_db_min\u001b[0m: -96.0, \n",
            "\u001b[0;33mbreathiness_smooth_width\u001b[0m: 0.12, \u001b[0;33mclip_grad_norm\u001b[0m: 1, \u001b[0;33mdataloader_prefetch_factor\u001b[0m: 2, \u001b[0;33mddp_backend\u001b[0m: nccl, \u001b[0;33mdictionary\u001b[0m: dictionaries/custom_dict.txt, \n",
            "\u001b[0;33mdiff_accelerator\u001b[0m: ddim, \u001b[0;33mdiff_decoder_type\u001b[0m: wavenet, \u001b[0;33mdiff_loss_type\u001b[0m: l2, \u001b[0;33mdropout\u001b[0m: 0.1, \u001b[0;33mds_workers\u001b[0m: 4, \n",
            "\u001b[0;33mdur_prediction_args\u001b[0m: {'arch': 'fs2', 'dropout': 0.1, 'hidden_size': 512, 'kernel_size': 3, 'lambda_pdur_loss': 0.3, 'lambda_sdur_loss': 3.0, 'lambda_wdur_loss': 1.0, 'log_offset': 1.0, 'loss_type': 'mse', 'num_layers': 5}, \u001b[0;33menc_ffn_kernel_size\u001b[0m: 9, \u001b[0;33menc_layers\u001b[0m: 4, \u001b[0;33menergy_db_max\u001b[0m: -12.0, \u001b[0;33menergy_db_min\u001b[0m: -96.0, \n",
            "\u001b[0;33menergy_smooth_width\u001b[0m: 0.12, \u001b[0;33mexp_name\u001b[0m: , \u001b[0;33mffn_act\u001b[0m: gelu, \u001b[0;33mffn_padding\u001b[0m: SAME, \u001b[0;33mfft_size\u001b[0m: 2048, \n",
            "\u001b[0;33mfinetune_ckpt_path\u001b[0m: None, \u001b[0;33mfinetune_enabled\u001b[0m: False, \u001b[0;33mfinetune_ignored_params\u001b[0m: ['model.spk_embed', 'model.fs2.txt_embed', 'model.fs2.encoder.embed_tokens'], \u001b[0;33mfinetune_strict_shapes\u001b[0m: True, \u001b[0;33mfmax\u001b[0m: 16000, \n",
            "\u001b[0;33mfmin\u001b[0m: 40, \u001b[0;33mfreezing_enabled\u001b[0m: False, \u001b[0;33mfrozen_params\u001b[0m: [], \u001b[0;33mhidden_size\u001b[0m: 256, \u001b[0;33mhop_size\u001b[0m: 512, \n",
            "\u001b[0;33minfer\u001b[0m: False, \u001b[0;33mlambda_dur_loss\u001b[0m: 1.0, \u001b[0;33mlambda_pitch_loss\u001b[0m: 1.0, \u001b[0;33mlambda_var_loss\u001b[0m: 1.0, \u001b[0;33mlog_interval\u001b[0m: 100, \n",
            "\u001b[0;33mlr_scheduler_args\u001b[0m: {'scheduler_cls': 'torch.optim.lr_scheduler.StepLR', 'step_size': 12000, 'gamma': 0.75}, \u001b[0;33mmax_batch_frames\u001b[0m: 80000, \u001b[0;33mmax_batch_size\u001b[0m: 9, \u001b[0;33mmax_beta\u001b[0m: 0.02, \u001b[0;33mmax_updates\u001b[0m: 288000, \n",
            "\u001b[0;33mmax_val_batch_frames\u001b[0m: 60000, \u001b[0;33mmax_val_batch_size\u001b[0m: 1, \u001b[0;33mmel_vmax\u001b[0m: 1.5, \u001b[0;33mmel_vmin\u001b[0m: -6, \u001b[0;33mmidi_smooth_width\u001b[0m: 0.06, \n",
            "\u001b[0;33mnum_ckpt_keep\u001b[0m: 5, \u001b[0;33mnum_heads\u001b[0m: 2, \u001b[0;33mnum_pad_tokens\u001b[0m: 1, \u001b[0;33mnum_sanity_val_steps\u001b[0m: 1, \u001b[0;33mnum_spk\u001b[0m: 1, \n",
            "\u001b[0;33mnum_valid_plots\u001b[0m: 10, \u001b[0;33moptimizer_args\u001b[0m: {'optimizer_cls': 'torch.optim.AdamW', 'lr': 0.0006, 'beta1': 0.9, 'beta2': 0.98, 'weight_decay': 0}, \u001b[0;33mpe\u001b[0m: parselmouth, \u001b[0;33mpe_ckpt\u001b[0m: None, \u001b[0;33mpermanent_ckpt_interval\u001b[0m: 10000, \n",
            "\u001b[0;33mpermanent_ckpt_start\u001b[0m: 180000, \u001b[0;33mpitch_prediction_args\u001b[0m: {'dilation_cycle_length': 5, 'pitd_clip_max': 12.0, 'pitd_clip_min': -12.0, 'pitd_norm_max': 8.0, 'pitd_norm_min': -8.0, 'repeat_bins': 64, 'residual_channels': 256, 'residual_layers': 20}, \u001b[0;33mpl_trainer_accelerator\u001b[0m: auto, \u001b[0;33mpl_trainer_devices\u001b[0m: auto, \u001b[0;33mpl_trainer_num_nodes\u001b[0m: 1, \n",
            "\u001b[0;33mpl_trainer_precision\u001b[0m: 32-true, \u001b[0;33mpl_trainer_strategy\u001b[0m: auto, \u001b[0;33mpndm_speedup\u001b[0m: 10, \u001b[0;33mpredict_breathiness\u001b[0m: False, \u001b[0;33mpredict_dur\u001b[0m: True, \n",
            "\u001b[0;33mpredict_energy\u001b[0m: False, \u001b[0;33mpredict_pitch\u001b[0m: True, \u001b[0;33mraw_data_dir\u001b[0m: ['/content/raw_data/diffsinger_db/pj_dat'], \u001b[0;33mrel_pos\u001b[0m: True, \u001b[0;33msampler_frame_count_grid\u001b[0m: 6, \n",
            "\u001b[0;33msave_codes\u001b[0m: ['configs', 'modules', 'training', 'utils'], \u001b[0;33mschedule_type\u001b[0m: linear, \u001b[0;33mseed\u001b[0m: 1234, \u001b[0;33msort_by_len\u001b[0m: True, \u001b[0;33mspeakers\u001b[0m: ['pj_dat'], \n",
            "\u001b[0;33mspk_ids\u001b[0m: [], \u001b[0;33mtask_cls\u001b[0m: training.variance_task.VarianceTask, \u001b[0;33mtest_prefixes\u001b[0m: ['pjs001_speech_seg000'], \u001b[0;33mtimesteps\u001b[0m: 1000, \u001b[0;33mtrain_set_name\u001b[0m: train, \n",
            "\u001b[0;33muse_pos_embed\u001b[0m: True, \u001b[0;33muse_spk_id\u001b[0m: False, \u001b[0;33mval_check_interval\u001b[0m: 100, \u001b[0;33mvalid_set_name\u001b[0m: valid, \u001b[0;33mvariances_prediction_args\u001b[0m: {'dilation_cycle_length': 4, 'residual_channels': 192, 'residual_layers': 10, 'total_repeat_bins': 48}, \n",
            "\u001b[0;33mvocoder\u001b[0m: , \u001b[0;33mvocoder_ckpt\u001b[0m: , \u001b[0;33mwin_size\u001b[0m: 2048, \u001b[0;33mwork_dir\u001b[0m: , \n",
            "| Binarizer:  <class 'preprocessing.variance_binarizer.VarianceBinarizer'>\n",
            "| spk_map:  {'pj_dat': 0}\n",
            "| load phoneme set: ['AP', 'SP', 'a', 'b', 'ch', 'd', 'e', 'g', 'h', 'i', 'j', 'k', 'm', 'my', 'n', 'o', 'r', 's', 'sh', 't', 'u', 'w', 'y']\n",
            "===== Phoneme Distribution Summary =====\n",
            "'AP': 4, 'SP': 8, 'a': 14, 'b': 2, 'ch': 2, 'd': 2, 'e': 4, 'g': 2, 'h': 2, 'i': 13,\n",
            "'j': 2, 'k': 2, 'm': 4, 'my': 4, 'n': 10, 'o': 41, 'r': 8, 's': 2, 'sh': 2, 't': 8,\n",
            "'u': 8, 'w': 3, 'y': 6\n",
            "| save summary to 't1/phoneme_distribution.jpg'\n",
            "===== MIDI Pitch Distribution Summary =====\n",
            "'A#2': 2, 'B2': 3, 'C3': 3, 'C#3': 3, 'D3': 2, 'D#3': 5, 'E3': 2, 'F3': 4, 'F#3': 3, 'G3': 2,\n",
            "'G#3': 2, 'A3': 7, 'A#3': 9, 'B3': 6, 'C4': 4, 'C#4': 1, 'D4': 12, 'D#4': 5, 'F4': 3\n",
            "| save summary to 't1/midi_distribution.jpg'\n",
            "100% 1/1 [00:11<00:00, 11.07s/it]\n",
            "| valid total duration: 6.67s\n",
            "100% 1/1 [00:01<00:00,  1.12s/it]\n",
            "| train total duration: 15.73s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "0J3b18EKdzMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Tensorboard\n",
        "#@markdown ___\n",
        "\n",
        "#@markdown For monitoring training progress. Enter the directory to your model save location (save_dir)\n",
        "\n",
        "#@markdown <font size=\"-1.5\"> if you are continuing from latest checkpoint, this would be the directory of a folder that you saved your model, it should have [lightning_logs] folder in it\n",
        "\n",
        "logs = \"\" #@param{type:\"string\"}\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir {logs}/lightning_logs"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ruKNxm_teUlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #Train your model\n",
        "%cd /content/DiffSinger\n",
        "\n",
        "#@markdown ___\n",
        "\n",
        "#@markdown ###**Only edit this section if you want to resume training**\n",
        "resume_training = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown <font size=\"-1.5\"> path to the config you got from training\n",
        "re_config_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown <font size=\"-1.5\"> path to the resume model's **FOLDER** (should mostlikely be the path you put above minus [ /config.yaml ])\n",
        "\n",
        "model_dir = \"\" #@param {type:\"string\"}\n",
        "\n",
        "if resume_training:\n",
        "    save_dir = model_dir\n",
        "    config_path = re_config_path\n",
        "    search_text = \"        args_work_dir = os.path.join(\"\n",
        "    replacement = f\"        args_work_dir = '{model_dir}'\"\n",
        "    with open(\"/content/DiffSinger/utils/hparams.py\", \"r\") as file:\n",
        "        lines = file.readlines()\n",
        "    for i, line in enumerate(lines):\n",
        "        if search_text in line:\n",
        "            lines[i] = replacement + \"\\n\"\n",
        "            break\n",
        "    with open(\"/content/DiffSinger/utils/hparams.py\", \"w\") as file:\n",
        "            file.writelines(lines)\n",
        "    #incase if anyone wanna change it lmao\n",
        "    search_text_alt = \"        args_work_dir = '\"\n",
        "    replacement_alt = f\"        args_work_dir = '{model_dir}'\"\n",
        "    with open(\"/content/DiffSinger/utils/hparams.py\", \"r\") as file:\n",
        "        lines = file.readlines()\n",
        "    for i, line in enumerate(lines):\n",
        "        if search_text_alt in line:\n",
        "            lines[i] = replacement_alt + \"\\n\"\n",
        "            break\n",
        "    with open(\"/content/DiffSinger/utils/hparams.py\", \"w\") as file:\n",
        "            file.writelines(lines)\n",
        "\n",
        "    relative_p = \"            relative_path = filepath.relative_to(Path('.').resolve())\"\n",
        "    relative_change = \"            relative_path = filepath.relative_to(Path('/content').resolve())\"\n",
        "    with open(\"/content/DiffSinger/utils/training_utils.py\", \"r\") as file:\n",
        "        lines = file.readlines()\n",
        "    for i, line in enumerate(lines):\n",
        "        if relative_p in line:\n",
        "            lines[i] = relative_change + \"\\n\"\n",
        "            break\n",
        "    with open(\"/content/DiffSinger/utils/training_utils.py\", \"w\") as file:\n",
        "            file.writelines(lines)\n",
        "    relative_p_2 = \"        relative_path = filepath.relative_to(Path('.').resolve())\"\n",
        "    relative_change_2 = \"        relative_path = filepath.relative_to(Path('/content').resolve())\"\n",
        "    with open(\"/content/DiffSinger/utils/training_utils.py\", \"r\") as file:\n",
        "        lines_2 = file.readlines()\n",
        "    for i, line in enumerate(lines):\n",
        "        if relative_p_2 in line:\n",
        "            lines_2[i] = relative_change_2 + \"\\n\"\n",
        "            break\n",
        "    with open(\"/content/DiffSinger/utils/training_utils.py\", \"w\") as file:\n",
        "            file.writelines(lines_2)\n",
        "    !cp {model_dir}/dictionary.txt /content/DiffSinger/dictionaries/custom_dict.txt\n",
        "\n",
        "else:\n",
        "    config_path = training_config\n",
        "\n",
        "if no_warn:\n",
        "    !CUDA_VISIBLE_DEVICES=0 python /content/DiffSinger/scripts/train.py --config {config_path} --exp_name {save_dir} --reset 2> /dev/null\n",
        "else:\n",
        "    !CUDA_VISIBLE_DEVICES=0 python /content/DiffSinger/scripts/train.py --config {config_path} --exp_name {save_dir} --reset"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Lu5w72UWgccC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Convert model to ONNX format**"
      ],
      "metadata": {
        "id": "FY40fGHEg9_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Build OpenUtau compatible voicebank\n",
        "#@markdown ___\n",
        "%cd /content\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "# to counter IF the user is to re-run this cell <3\n",
        "if os.path.exists(\"/content/OU_compatible_files\"):\n",
        "    shutil.rmtree(\"/content/OU_compatible_files\")\n",
        "    os.remove(\"/content/jpn_dict.txt\")\n",
        "else:\n",
        "    pass\n",
        "\n",
        "#@markdown <font size=\"-1.5\"> select this if you don't want to see the onnx converter's output\n",
        "no_output = True # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown <font size=\"-1.5\"> path to your **ACOUSTIC CHECKPOINT**: automatically use latest checkpoint that is in the same folder\n",
        "acoustic_checkpoint_path = \"\" #@param{type:\"string'}\n",
        "acoustic_folder_name = os.path.basename(os.path.dirname(acoustic_checkpoint_path)) + \"_acoustic\"\n",
        "acoustic_folder_path = os.path.dirname(acoustic_checkpoint_path)\n",
        "\n",
        "#@markdown <font size=\"-1.5\"> path to your **VARIANCE CHECKPOINT** (leave blank if you don't have any): automatically use latest checkpoint that is in the same folder\n",
        "variance_checkpoint_path = \"\" #@param{type:\"string'}\n",
        "variance_folder_name = os.path.basename(os.path.dirname(variance_checkpoint_path)) + \"_variance\"\n",
        "variance_folder_path = os.path.dirname(variance_checkpoint_path)\n",
        "\n",
        "#@markdown <font size=\"-1.5\"> path to your word to phoneme dict (leave blank to use default Japanese dict)\n",
        "dictionary_path = \"\" #@param{type:\"string\"}\n",
        "\n",
        "#@markdown <font size=\"-1.5\"> path to where you want to save your OpenUtau bank\n",
        "exp_folder = \"\" #@param{type:\"string\"}\n",
        "\n",
        "acoustic_onnx_exp = exp_folder + \"/onnx/acoustic\"\n",
        "variance_onnx_exp = exp_folder + \"/onnx/variance\"\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"getting base files...\")\n",
        "\n",
        "!mkdir -p /content/OU_compatible_files/enunux_base\n",
        "!mkdir -p /content/OU_compatible_files/variance_base\n",
        "!wget https://github.com/MLo7Ghinsan/DiffSinger_colab_notebook_MLo7/releases/download/OU_files/enunux_base.zip >/dev/null 2>&1\n",
        "!wget https://github.com/MLo7Ghinsan/DiffSinger_colab_notebook_MLo7/releases/download/OU_files/variance_base.zip >/dev/null 2>&1\n",
        "!wget https://github.com/MLo7Ghinsan/DiffSinger_colab_notebook_MLo7/releases/download/OU_files/jpn_dict.txt >/dev/null 2>&1\n",
        "!unzip -q /content/enunux_base.zip -d /content/OU_compatible_files/enunux_base\n",
        "!unzip -q /content/variance_base.zip -d /content/OU_compatible_files/variance_base\n",
        "!rm /content/enunux_base.zip\n",
        "!rm /content/variance_base.zip\n",
        "\n",
        "!cp {acoustic_checkpoint_path} -r /content/DiffSinger/checkpoints/{acoustic_folder_name}\n",
        "!cp {acoustic_folder_path}/config.yaml -r /content/DiffSinger/checkpoints/{acoustic_folder_name}\n",
        "!cp {acoustic_folder_path}/dictionary.txt -r /content/DiffSinger/checkpoints/{acoustic_folder_name} # i dont think this is needed but its only one file oh well\n",
        "!cp {acoustic_folder_path}/spk_map.json -r /content/DiffSinger/checkpoints/{acoustic_folder_name}\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"converting acoustic to onnx...\")\n",
        "search_text = \"        args_work_dir = os.path.join(\"\n",
        "replacement = f\"        args_work_dir = '{acoustic_folder_path}'\"\n",
        "with open(\"/content/DiffSinger/utils/hparams.py\", \"r\") as file:\n",
        "    lines = file.readlines()\n",
        "for i, line in enumerate(lines):\n",
        "    if search_text in line:\n",
        "        lines[i] = replacement + \"\\n\"\n",
        "        break\n",
        "with open(\"/content/DiffSinger/utils/hparams.py\", \"w\") as file:\n",
        "        file.writelines(lines)\n",
        "#incase if anyone wanna change it lmao\n",
        "search_text_alt = \"        args_work_dir = '\"\n",
        "replacement_alt = f\"        args_work_dir = '{acoustic_folder_path}'\"\n",
        "with open(\"/content/DiffSinger/utils/hparams.py\", \"r\") as file:\n",
        "    lines = file.readlines()\n",
        "for i, line in enumerate(lines):\n",
        "    if search_text_alt in line:\n",
        "        lines[i] = replacement_alt + \"\\n\"\n",
        "        break\n",
        "with open(\"/content/DiffSinger/utils/hparams.py\", \"w\") as file:\n",
        "        file.writelines(lines)\n",
        "\n",
        "if no_output:\n",
        "    !python /content/DiffSinger/scripts/export.py acoustic --exp {acoustic_folder_name} --out {exp_folder}/onnx/acoustic >/dev/null 2>&1\n",
        "else:\n",
        "    !python /content/DiffSinger/scripts/export.py acoustic --exp {acoustic_folder_name} --out {exp_folder}/onnx/acoustic\n",
        "\n",
        "\n",
        "if not variance_checkpoint_path:\n",
        "    print(\"\\n\")\n",
        "    print(\"variance ckeckpoint path not specified, using enunux instead...\")\n",
        "else:\n",
        "    print(\"\\n\")\n",
        "    print(\"converting variance to onnx...\")\n",
        "    !cp {variance_checkpoint_path} -r /content/DiffSinger/checkpoints/{variance_folder_name}\n",
        "    !cp {variance_folder_path}/config.yaml -r /content/DiffSinger/checkpoints/{variance_folder_name}\n",
        "    !cp {variance_folder_path}/dictionary.txt -r /content/DiffSinger/checkpoints/{variance_folder_name} # i dont think this is needed but its only one file oh well\n",
        "    !cp {variance_folder_path}/spk_map.json -r /content/DiffSinger/checkpoints/{variance_folder_name}\n",
        "    search_text = \"        args_work_dir = os.path.join(\"\n",
        "    replacement = f\"        args_work_dir = '{variance_folder_path}'\"\n",
        "    with open(\"/content/DiffSinger/utils/hparams.py\", \"r\") as file:\n",
        "        lines = file.readlines()\n",
        "    for i, line in enumerate(lines):\n",
        "        if search_text in line:\n",
        "            lines[i] = replacement + \"\\n\"\n",
        "            break\n",
        "    with open(\"/content/DiffSinger/utils/hparams.py\", \"w\") as file:\n",
        "            file.writelines(lines)\n",
        "    #incase if anyone wanna change it lmao\n",
        "    search_text_alt = \"        args_work_dir = '\"\n",
        "    replacement_alt = f\"        args_work_dir = '{variance_folder_path}'\"\n",
        "    with open(\"/content/DiffSinger/utils/hparams.py\", \"r\") as file:\n",
        "        lines = file.readlines()\n",
        "    for i, line in enumerate(lines):\n",
        "        if search_text_alt in line:\n",
        "            lines[i] = replacement_alt + \"\\n\"\n",
        "            break\n",
        "    with open(\"/content/DiffSinger/utils/hparams.py\", \"w\") as file:\n",
        "            file.writelines(lines)\n",
        "    if no_output:\n",
        "        !python /content/DiffSinger/scripts/export.py variance --exp {variance_folder_name} --out {exp_folder}/onnx/variance >/dev/null 2>&1\n",
        "    else:\n",
        "        !python /content/DiffSinger/scripts/export.py variance --exp {variance_folder_name} --out {exp_folder}/onnx/variance\n",
        "\n",
        "if not variance_checkpoint_path:\n",
        "    folder_paths = [acoustic_onnx_exp]\n",
        "else:\n",
        "    folder_paths = [acoustic_onnx_exp, variance_onnx_exp]\n",
        "\n",
        "#renaming these so its gonna be easier\n",
        "patterns = {\"acoustic.onnx\": \"acoustic.onnx\", \"dur.onnx\": \"dur.onnx\", \"linguistic.onnx\": \"linguistic.onnx\", \"pitch.onnx\": \"pitch.onnx\", \"variance.onnx\": \"variance.onnx\", \"phonemes.txt\": \"phonemes.txt\"}\n",
        "\n",
        "\n",
        "for folder_path in folder_paths:\n",
        "    for filename in os.listdir(folder_path):\n",
        "        for pattern, new_name in patterns.items():\n",
        "            if pattern in filename:\n",
        "                old_path = os.path.join(folder_path, filename)\n",
        "                new_path = os.path.join(folder_path, new_name)\n",
        "                if os.path.exists(old_path):\n",
        "                    os.rename(old_path, new_path)\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"writing dsdict.yaml...\")\n",
        "\n",
        "if not dictionary_path:\n",
        "    dict_path = \"/content/jpn_dict.txt\"\n",
        "else:\n",
        "    dict_path = dictionary_path\n",
        "\n",
        "# for symbols list\n",
        "phoneme_dict_path = f\"{acoustic_folder_path}/dictionary.txt\"\n",
        "\n",
        "dsdict = \"dsdict.yaml\"\n",
        "\n",
        "def parse_phonemes(phonemes_str):\n",
        "    return phonemes_str.split()\n",
        "\n",
        "entries = []\n",
        "vowel_types = {\"a\", \"i\", \"u\", \"e\", \"o\", \"N\", \"M\", \"NG\", \"cl\", \"vf\"}\n",
        "vowel_data = []\n",
        "stop_data = []\n",
        "\n",
        "# Process the specified dictionary\n",
        "with open(dict_path, \"r\") as f:\n",
        "    for line in f:\n",
        "        word, phonemes_str = line.strip().split(\"\\t\")\n",
        "        phonemes = parse_phonemes(phonemes_str)\n",
        "        if len(phonemes) == 1:\n",
        "            entries.append({\"grapheme\": word, \"phonemes\": phonemes})\n",
        "        else:\n",
        "            entries.append({\"grapheme\": word, \"phonemes\": phonemes})\n",
        "\n",
        "with open(phoneme_dict_path, \"r\") as f:\n",
        "    for line in f:\n",
        "        phoneme, _ = line.strip().split(\"\\t\")\n",
        "        phoneme_type = \"vowel\" if phoneme[0] in vowel_types else \"stop\"\n",
        "        entry = {\"symbol\": phoneme, \"type\": phoneme_type}\n",
        "        if phoneme_type == \"vowel\":\n",
        "            vowel_data.append(entry)\n",
        "        else:\n",
        "            stop_data.append(entry)\n",
        "\n",
        "vowel_data.sort(key=lambda x: x[\"symbol\"])\n",
        "stop_data.sort(key=lambda x: x[\"symbol\"])\n",
        "\n",
        "dsdict_path = os.path.join(\"/content/OU_compatible_files\", dsdict)\n",
        "with open(dsdict_path, \"w\") as f:\n",
        "    f.write(\"entries:\\n\")\n",
        "    for entry in entries:\n",
        "        f.write(f\"- grapheme: {entry['grapheme']}\\n\")\n",
        "        f.write(\"  phonemes:\\n\")\n",
        "        for phoneme in entry[\"phonemes\"]:\n",
        "            f.write(f\"  - {phoneme}\\n\")\n",
        "\n",
        "    f.write(\"\\nsymbols:\\n\")\n",
        "    for entry in vowel_data + stop_data:\n",
        "        f.write(f\"- symbol: {entry['symbol']}\\n\")\n",
        "        f.write(f\"  type: {entry['type']}\\n\")\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"putting your vb together...\")\n",
        "\n",
        "if not variance_checkpoint_path:\n",
        "    acoustic_1 = f\"{acoustic_onnx_exp}\" + \"/acoustic.onnx\"\n",
        "    !rm /content/OU_compatible_files/enunux_base/acoustic.onnx\n",
        "    !cp {acoustic_1} /content/OU_compatible_files/enunux_base >/dev/null 2>&1\n",
        "    !rm /content/OU_compatible_files/enunux_base/phonemes.txt\n",
        "    !cp {exp_folder}/onnx/acoustic/phonemes.txt /content/OU_compatible_files/enunux_base >/dev/null 2>&1\n",
        "    !cp {dsdict_path} /content/OU_compatible_files/enunux_base >/dev/null 2>&1 #enunux doesnt need this but it doesnt hurt to include this file with it\n",
        "    !mv /content/OU_compatible_files/enunux_base /content/OU_compatible_files/OU_voicebank\n",
        "    folder_to_zip = \"/content/OU_compatible_files/OU_voicebank\"\n",
        "    output_zip_filename = exp_folder + \"/OU_voicebank.zip\"\n",
        "    with zipfile.ZipFile(output_zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk(folder_to_zip):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                relative_path = os.path.relpath(file_path, folder_to_zip)\n",
        "                zipf.write(file_path, relative_path)\n",
        "else:\n",
        "    acoustic_1 = f\"{acoustic_onnx_exp}\" + \"/acoustic.onnx\"\n",
        "    variance_1 = f\"{variance_onnx_exp}\" + \"/variance.onnx\"\n",
        "    variance_2 = f\"{variance_onnx_exp}\" + \"/pitch.onnx\"\n",
        "    variance_3 = f\"{variance_onnx_exp}\" + \"/dur.onnx\"\n",
        "    variance_4 = f\"{variance_onnx_exp}\" + \"/linguistic.onnx\"\n",
        "    !rm /content/OU_compatible_files/variance_base/acoustic.onnx\n",
        "    !cp {acoustic_1} /content/OU_compatible_files/variance_base >/dev/null 2>&1\n",
        "    !rm /content/OU_compatible_files/variance_base/linguistic.onnx\n",
        "    !cp {variance_4} /content/OU_compatible_files/variance_base >/dev/null 2>&1\n",
        "    !rm /content/OU_compatible_files/variance_base/dsvariance/variance.onnx\n",
        "    !cp {variance_1} /content/OU_compatible_files/variance_base/dsvariance/variance.onnx >/dev/null 2>&1\n",
        "    !rm /content/OU_compatible_files/variance_base/dspitch/pitch.onnx\n",
        "    !cp {variance_2} /content/OU_compatible_files/variance_base/dspitch/pitch.onnx >/dev/null 2>&1\n",
        "    !rm /content/OU_compatible_files/variance_base/dsdur/dur.onnx\n",
        "    !cp {variance_3} /content/OU_compatible_files/variance_base/dsdur/dur.onnx >/dev/null 2>&1\n",
        "    !rm /content/OU_compatible_files/variance_base/phonemes.txt\n",
        "    !cp {exp_folder}/onnx/acoustic/phonemes.txt /content/OU_compatible_files/variance_base\n",
        "    !rm /content/OU_compatible_files/variance_base/dsdict.yaml\n",
        "    !cp {dsdict_path} /content/OU_compatible_files/variance_base\n",
        "    !mv /content/OU_compatible_files/variance_base /content/OU_compatible_files/OU_voicebank\n",
        "    folder_to_zip = \"/content/OU_compatible_files/OU_voicebank\"\n",
        "    output_zip_filename = exp_folder + \"/OU_voicebank.zip\"\n",
        "    with zipfile.ZipFile(output_zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk(folder_to_zip):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                relative_path = os.path.relpath(file_path, folder_to_zip)\n",
        "                zipf.write(file_path, relative_path)\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Go extract and edit character.txt and character.yaml to your liking for OpenUtau <3\")\n"
      ],
      "metadata": {
        "id": "x33iZhZchEMW",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Miscellaneous**\n",
        "###### (This is an archive section, will either be removed or changed to something else)"
      ],
      "metadata": {
        "id": "4sbU1aH5kGFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "#@title Generate enunux.yaml (not including grapheme)\n",
        "\n",
        "#@markdown <font size=\"-2.5\"> path to your dictionary.txt\n",
        "\n",
        "dict_path = \"\" #@param{type:\"string'}\n",
        "enunux = \"enunux.yaml\"\n",
        "vowel_types = {\"a\", \"i\", \"u\", \"e\", \"o\", \"N\", \"M\", \"NG\"}\n",
        "enunux_data = []\n",
        "vowel_data = []\n",
        "stop_data = []\n",
        "with open(dict_path, \"r\") as f:\n",
        "    for line in f:\n",
        "        phoneme, _ = line.strip().split(\"\\t\")\n",
        "        phoneme_type = \"vowel\" if phoneme[0] in vowel_types else \"stop\"\n",
        "        entry = f\"- {{\\\"symbol\\\": \\\"{phoneme}\\\", \\\"type\\\": \\\"{phoneme_type}\\\"}}\"\n",
        "        if phoneme_type == \"vowel\":\n",
        "            vowel_data.append(entry)\n",
        "        else:\n",
        "            stop_data.append(entry)\n",
        "vowel_data.sort()\n",
        "stop_data.sort()\n",
        "enunux_data.extend([\"# Vowel type symbols:\", *vowel_data, \"\", \"# Stop type symbols:\", *stop_data])\n",
        "directory = os.path.dirname(dict_path)\n",
        "enunux_path = os.path.join(directory, enunux)\n",
        "with open(enunux_path, \"w\") as f:\n",
        "    f.write(\"symbols:\\n\")\n",
        "    f.write(\"\\n\".join(enunux_data))\n",
        "    f.write(\"\\n\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LMHTaub-kMSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Last Section Note\n",
        "Wow you made it to the very bottom.... Why though lmao hahahahhshahhasdksajidhasjl\n",
        "\n",
        "Anyways, now that you are here i guess ill tell you my plan/todo list for this notebook \\\n",
        "Feel free to suggest or ask any question via [discord](https://discord.com/invite/wwbu2JUMjj) my user display name is MLo7 and my user name is ghin_mlo7\n",
        "\n",
        "todo list:\n",
        "- add option to use pretrained model\n",
        "- add enable/disable checks for breathiness and energy training[**THESE TWO OPTIONS ARE OFF BY DEFAULT**]\n",
        "- add link to vocoder training notebook (yet to be ready) or add a vocoder training section"
      ],
      "metadata": {
        "id": "Ljl8Yr6wM3Ma"
      }
    }
  ]
}