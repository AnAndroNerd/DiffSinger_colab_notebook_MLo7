{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MLo7Ghinsan/DiffSinger_colab_notebook_MLo7/blob/main/lab_base_maker_AutoLabelingForSVS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook for automatic `txt` transcription and `lab` generation\n",
        "\n",
        "Original notebook by PixPrucer\n",
        "\n",
        "Edited by MLo7\n",
        "\n",
        "zip format example:\n",
        "<pre>\n",
        "your_zip.zip:                              ###NO SUBFOLDER INSIDE THE ZIP###\n",
        "    |\n",
        "    |\n",
        "    data_1.wav\n",
        "    data_1.txt (optional)\n",
        "    .\n",
        "    data_2.wav\n",
        "    data_2.txt (optional)\n",
        "    .\n",
        "    data_3.wav\n",
        "    data_3.txt (optional)\n",
        "    .\n",
        "    ...\n",
        "</pre>\n",
        "\n",
        "Reccomend audio length: 3~15 seconds per wav file"
      ],
      "metadata": {
        "id": "n7q_yEdpYUgB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8eiFkpuYMo4",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title # Mount Drive and install Conda\n",
        "#@markdown Basically installs all necesarry things for the notebook to work <br/> **Wait until it restarts your session !**\n",
        "#@markdown Mount Drive\n",
        "from IPython.display import clear_output\n",
        "from google.colab import drive\n",
        "\n",
        "%cd /content\n",
        "drive.mount('/content/drive')\n",
        "!pip install -q condacolab\n",
        "clear_output() # rawr\n",
        "\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Main installation\n",
        "\n",
        "%cd /content\n",
        "!conda create -n aligner -c conda-forge montreal-forced-aligner==2.0.6\n",
        "# Download Model\n",
        "!source activate aligner; \\\n",
        "mfa model download acoustic english_us_arpa\n",
        "!mkdir /content/jpmodel\n",
        "!wget https://cdn.discordapp.com/attachments/816517150175920138/1133350036995059732/jpn_dict_4_autoalign_colab.txt #edited file\n",
        "!wget https://huggingface.co/datasets/fox7005/tool/resolve/main/jp_acoustic_model.zip\n",
        "# Download G2P\n",
        "!source activate aligner; \\\n",
        "mfa model download dictionary english_us_arpa\n",
        "# HAI-D's TextGrid-->LAB\n",
        "!wget https://cdn.discordapp.com/attachments/816517150175920138/1161903924903677982/textgrid2lab.py #edited file\n",
        "!wget https://cdn.discordapp.com/attachments/1004785092129996850/1093284704599412906/converter.txt\n",
        "# Arpabet phoneme mapping table\n",
        "!pip install openai-whisper\n",
        "!pip install pykakasi\n",
        "!pip install mytextgrid"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NxGpCHv58Q38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Unzip corpus\n",
        "from IPython.display import clear_output\n",
        "\n",
        "#@markdown Unzip your dataset for transcription stuff. Make sure it is an archive only containing wavs (3~15 seconds in length recommended).\n",
        "\n",
        "file_location = '' #@param {type:\"string\"}\n",
        "\n",
        "!7z x \"$file_location\" -o/content/db"
      ],
      "metadata": {
        "id": "C8pFl6vuZklY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Whisper & MFA inference\n",
        "#@markdown **Make transcriptions** <br/> Worth noting that your singing database shouldn't have long pauses, *ooh-ing*, lalala-ing, humming etc. in it, otherwise it'll probably break the transcription making (Whisper poorly recognises those).\n",
        "#Implemented from https://github.com/openai/whisper/discussions/1041 by Haru0l\n",
        "import os\n",
        "import pykakasi\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "%cd /content\n",
        "clear_output()\n",
        "\n",
        "#@markdown Select this if you have your own transcription along with your wav (so it wont transcribe them)\n",
        "user_transcripts = False # @param {type:\"boolean\"}\n",
        "\n",
        "language = \"JPN (Japanese)\" #@param [\"JPN (Japanese)\", \"ENG (English)\", \"rawr x3\"]\n",
        "\n",
        "#@markdown The higher the number, the better alignment will be i guess, it's a hit or miss though\n",
        "beam = 10 # @param {type:\"slider\", min:10, max:2000, step:10}\n",
        "retry_beam = beam * 4\n",
        "\n",
        "if not user_transcripts:\n",
        "    if language == \"JPN (Japanese)\":\n",
        "        !whisper --model medium -f txt --language ja --output_dir /content/db /content/db/*.wav\n",
        "        #sussy stuff to make it work lmao\n",
        "        folder_path = \"/content/db\"\n",
        "        kakasi = pykakasi.kakasi()\n",
        "        kakasi.setMode(\"J\", \"H\")\n",
        "        kakasi.setMode(\"K\", \"H\")\n",
        "        conv = kakasi.getConverter()\n",
        "\n",
        "        def add_space(text):\n",
        "            special_combinations = [\"きゃ\", \"きゅ\", \"きょ\", \"しゃ\", \"しゅ\", \"しょ\", \"ちゃ\", \"ちゅ\", \"ちょ\", \"にゃ\", \"にゅ\", \"にょ\", \"ひゃ\", \"ひゅ\", \"ひょ\", \"みゃ\", \"みゅ\", \"みょ\", \"りゃ\", \"りゅ\", \"りょ\"]\n",
        "            result = []\n",
        "            buffer = \"\"\n",
        "            for char in text:\n",
        "                if buffer + char in special_combinations:\n",
        "                    buffer += char\n",
        "                else:\n",
        "                    if buffer:\n",
        "                        result.append(buffer)\n",
        "                    buffer = char\n",
        "            if buffer:\n",
        "                result.append(buffer)\n",
        "            return \" \".join(result)\n",
        "\n",
        "        def remove_space(text):\n",
        "            return \" \".join(text.split())\n",
        "\n",
        "        for file_name in os.listdir(folder_path):\n",
        "            if file_name.endswith(\".txt\"):\n",
        "                file_path = os.path.join(folder_path, file_name)\n",
        "                with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "                    japanese_text = file.read()\n",
        "                hiragana_text = conv.do(japanese_text)\n",
        "                hiragana_add = add_space(hiragana_text)\n",
        "                hiraganaur = remove_space(hiragana_add)\n",
        "                with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "                    file.write(hiraganaur)\n",
        "\n",
        "\n",
        "    elif language == \"ENG (English)\":\n",
        "        def Transcriber(audiofile):\n",
        "            import whisper\n",
        "            from whisper.tokenizer import get_tokenizer\n",
        "\n",
        "            #encourage model to transcribe words literally\n",
        "            tokenizer = get_tokenizer(multilingual=False)  # use multilingual=True if using multilingual model\n",
        "            number_tokens = [\n",
        "                i\n",
        "                for i in range(tokenizer.eot)\n",
        "                if all(c in \"0123456789\" for c in tokenizer.decode([i]).removeprefix(\" \"))\n",
        "            ]\n",
        "\n",
        "            model = whisper.load_model(\"medium.en\")\n",
        "            answer = model.transcribe(audiofile, suppress_tokens=[-1] + number_tokens)\n",
        "\n",
        "            print(answer['text'])\n",
        "\n",
        "            output_txt = os.path.join('/content/db/', os.path.splitext(filename)[0] + '.txt')\n",
        "\n",
        "            with open(output_txt, 'w') as f:\n",
        "              f.write(answer['text'])\n",
        "\n",
        "        for filename in os.listdir('/content/db/'):\n",
        "          if filename.endswith('.wav'):\n",
        "            file_path = os.path.join('/content/db/', filename)\n",
        "            Transcriber(file_path)\n",
        "    else:\n",
        "        print(\"rawr xd nuzzle pounces on you uwu you so warm\")\n",
        "else:\n",
        "    pass\n",
        "\n",
        "#**Make alignments**\n",
        "%cd /content\n",
        "\n",
        "if language == \"JPN (Japanese)\":\n",
        "    print(\"You've selected [JPN]\")\n",
        "    !source activate aligner; \\\n",
        "    mfa align /content/db /content/jpn_dict_4_autoalign_colab.txt /content/jp_acoustic_model.zip /content/alignment --beam {beam} --retry_beam {retry_beam} --clean\n",
        "\n",
        "elif language == \"ENG (English)\":\n",
        "    print(\"You've selected [ENG]\")\n",
        "    !source activate aligner; \\\n",
        "    mfa align /content/db english_us_arpa english_us_arpa /content/alignment --beam {beam} --retry_beam {retry_beam} --clean\n",
        "\n",
        "else:\n",
        "    print(\"You've selected the uwu\")\n",
        "#mfa align --custom_mapping_path /content/arpa_cleaners.yaml /content/db english_us_arpa english_us_arpa /content/alignment\n",
        "# Thank u HAI-D I'd probably die figuring out myself\n",
        "\n",
        "#**Convert to LAB format**\n",
        "%cd /content\n",
        "!python /content/textgrid2lab.py"
      ],
      "metadata": {
        "id": "IzJupF7Duiuw",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Zips up labels `lab` for you to dowload (through colab's file explorer)\n",
        "!zip labels.zip /content/alignment/*.lab"
      ],
      "metadata": {
        "id": "oFf5Mx4LHaTY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You might want to adjust the labels after using vLabeler. I like to treat those as a baseline for hand-labelling (makes the job just. Slightly easier)"
      ],
      "metadata": {
        "id": "o-9QAVD55mDb"
      }
    }
  ]
}