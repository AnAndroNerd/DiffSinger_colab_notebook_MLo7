{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOQ2Mc1KSASzONuTfWDy0K0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MLo7Ghinsan/DiffSinger_colab_notebook_MLo7/blob/main/NSF_hifigan_finetuning_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zW_ptHQW9FXh",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title # Mount Google Drive and Setup\n",
        "\n",
        "\n",
        "#ill put the imports here too ig\n",
        "from IPython.display import clear_output\n",
        "import os\n",
        "import shutil\n",
        "import yaml\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "!rm -rf /content/sample_data\n",
        "!git clone https://github.com/openvpi/DiffSinger.git\n",
        "!git clone https://github.com/openvpi/SingingVocoders\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install click einops h5py librosa lightning matplotlib mido numpy praat-parselmouth preprocessing pyworld PyYAML torchmetrics tqdm\n",
        "#for onnx export\n",
        "!pip install onnx onnxruntime onnxsim\n",
        "!apt-get install aria2\n",
        "#this is here bc it wouldnt work with base_task.py so we just use base_task_gan.py for it\n",
        "shutil.copy(\"/content/SingingVocoders/training/base_task_gan.py\", \"/content/SingingVocoders/training/base_task.py\")\n",
        "clear_output()\n",
        "!aria2c https://github.com/openvpi/SingingVocoders/releases/download/v0.0.1/hifi.7z\n",
        "!aria2c https://github.com/openvpi/DiffSinger/releases/download/v2.1.0/rmvpe.zip\n",
        "!7z x /content/hifi.7z -o/content/SingingVocoders/pretrained/hifigan\n",
        "!7z x /content/rmvpe.zip -o/content/SingingVocoders/pretrained\n",
        "!rm /content/hifi.7z\n",
        "!rm /content/rmvpe.zip\n",
        "clear_output()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Extract Data\n",
        "#@markdown ___\n",
        "\n",
        "import re\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "\n",
        "#@markdown Path to zip file containing your audio data\n",
        "data_zip_path = \"\" # @param {type:\"string\"}\n",
        "\n",
        "#markdown Config type you want to use (this one is permanent for now)\n",
        "#train_config = \"hifigan\" # @param [\"hifigan\"]\n",
        "\n",
        "#@markdown Pitch extractor algorithm\n",
        "f0_ext = \"parselmouth\" # @param [\"parselmouth\", \"rmvpe\"]\n",
        "\n",
        "#@markdown Precision option\n",
        "precision = \"16-mixed\" # @param [\"32-true\", \"bf16-mixed\", \"16-mixed\"]\n",
        "\n",
        "#@markdown data aug option\n",
        "data_aug = True # @param {type:\"boolean\"}\n",
        "data_aug_probability = 0.5 # @param {type:\"slider\", min:0.1, max:3, step:0.1}\n",
        "\n",
        "\n",
        "#@markdown Model save interval\n",
        "save_interval = 2000 # @param {type:\"slider\", min:100, max:10000, step:100}\n",
        "save_interval = int(save_interval / 2)\n",
        "\n",
        "#@markdown Amount of validation files you want to use (can't exceed the amount of train files)\n",
        "val_amount = 8 # @param {type:\"slider\", min:1, max:18, step:1}\n",
        "\n",
        "\n",
        "train_path = \"/content/audio_data/input\"\n",
        "npz_path = \"/content/audio_data/output\"\n",
        "\n",
        "\n",
        "!rm -rf /content/audio_data >/dev/null 2>&1\n",
        "\n",
        "if not os.path.exists(train_path):\n",
        "    os.makedirs(train_path)\n",
        "    os.makedirs(npz_path)\n",
        "!7z e \"$data_zip_path\" -o{train_path} *.wav -r\n",
        "\n",
        "#audio resample to avoid errors\n",
        "sample_rate = 44100\n",
        "def resample_and_convert_audio(audio_path, sample_rate):\n",
        "    audio, sr = librosa.load(audio_path, sr=None)\n",
        "    if sr != sample_rate:\n",
        "        audio = librosa.resample(audio, orig_sr=sr, target_sr=sample_rate)\n",
        "    sf.write(audio_path, audio, sample_rate)\n",
        "    wav_name = os.path.basename(audio_path)\n",
        "    print(f\"Resample {wav_name} to {sample_rate}\")\n",
        "for root, dirs, files in os.walk(train_path):\n",
        "    for file in files:\n",
        "        if file.endswith(\".wav\"):\n",
        "            audio_path = os.path.join(root, file)\n",
        "            resample_and_convert_audio(audio_path, sample_rate)\n",
        "\n",
        "with open(\"/content/SingingVocoders/configs/ft_hifigan.yaml\", \"r\") as config:\n",
        "    ew = yaml.safe_load(config)\n",
        "ew[\"data_input_path\"] = [\"/content/audio_data/input\"]\n",
        "ew[\"data_out_path\"] = [\"/content/audio_data/output\"]\n",
        "ew[\"val_num\"] = val_amount\n",
        "if data_aug:\n",
        "    ew[\"key_aug\"] = data_aug\n",
        "    ew[\"key_aug_prob\"] = data_aug_probability\n",
        "with open(\"/content/SingingVocoders/configs/ft_hifigan.yaml\", \"w\") as config:\n",
        "    yaml.dump(ew, config)\n",
        "\n",
        "with open(\"/content/SingingVocoders/configs/ft_hifigan.yaml\", \"r\") as config:\n",
        "    ew = yaml.safe_load(config)\n",
        "ew[\"pe\"] = f0_ext\n",
        "ew[\"val_check_interval\"] = save_interval #questionable\n",
        "ew[\"pl_trainer_accelerator\"] = \"gpu\"\n",
        "ew[\"pl_trainer_precision\"] = precision\n",
        "ew[\"finetune_ckpt_path\"] = \"/content/SingingVocoders/pretrained/hifigan/hifi.ckpt\"\n",
        "with open(\"/content/SingingVocoders/configs/ft_hifigan.yaml\", \"w\") as config:\n",
        "    yaml.dump(ew, config)\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "WjKHanCFErik",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Preprocess\n",
        "#@markdown ___\n",
        "# edit the f0 min and max for parselmouth\n",
        "import re\n",
        "f0_min = 12 #C0\n",
        "f0_max = 2100 #about C7\n",
        "wav2F0_path = \"/content/SingingVocoders/utils/wav2F0.py\"\n",
        "with open(wav2F0_path, \"r\") as f:\n",
        "    change_min_max = f.read()\n",
        "change_min_max = re.sub(r\"f0_min\\s*=\\s*\\d+\", f'f0_min = {f0_min}', change_min_max)\n",
        "change_min_max = re.sub(r\"f0_max\\s*=\\s*\\d+\", f'f0_max = {f0_max}', change_min_max)\n",
        "with open(wav2F0_path, \"w\") as f:\n",
        "    f.write(change_min_max)\n",
        "\n",
        "with open(\"/content/SingingVocoders/process.py\", \"r\") as f:\n",
        "    process_py_read = f.read()\n",
        "process_py_read = re.sub(r\"val_set\\s*=\\s*.*\", f\"val_set = random.choices(list(data_filename_set), k=val_num)\", process_py_read)\n",
        "with open(\"/content/SingingVocoders/process.py\", \"w\") as f:\n",
        "    f.write(process_py_read)\n",
        "\n",
        "%cd /content/SingingVocoders\n",
        "!python /content/SingingVocoders/process.py --config /content/SingingVocoders/configs/ft_hifigan.yaml --strx 1\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "NoE5hWf-l54W",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Tensorboard\n",
        "#@markdown ___\n",
        "\n",
        "#@markdown path to your save dir basically\n",
        "logdir = \"\" # @param {type:\"string\"}\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir {logdir}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JH_UodJ0QWYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/SingingVocoders\n",
        "#@title # Training\n",
        "#@markdown ___\n",
        "\n",
        "config_path = \"/content/SingingVocoders/configs/ft_hifigan.yaml\" # @param {type:\"string\"}\n",
        "exp_name = \"\" # @param {type:\"string\"}\n",
        "save_path = \"\" # @param {type:\"string\"}\n",
        "\n",
        "import re\n",
        "\n",
        "training_utils_path = \"/content/SingingVocoders/utils/training_utils.py\"\n",
        "with open(training_utils_path, \"r\") as f:\n",
        "    edit_relative_path = f.read()\n",
        "new_relative = \"relative_path = filepath.relative_to(Path('/content').resolve())\"\n",
        "pattern = r\"relative_path\\s*=\\s*.*\"\n",
        "edit_relative_path = re.sub(pattern, new_relative, edit_relative_path)\n",
        "with open(training_utils_path, \"w\") as f:\n",
        "    f.write(edit_relative_path)\n",
        "\n",
        "!python /content/SingingVocoders/train.py --config {config_path} --exp_name {exp_name} --work_dir {save_path}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "s_zvFSHo5V8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Export ONNX\n",
        "#@markdown ___\n",
        "#test exporting because the export_ckpt.py script is you know dying\n",
        "#this is a must before using diffsinger export script\n",
        "import torch\n",
        "import json\n",
        "import os\n",
        "\n",
        "#@markdown path to your vocoder ckpt\n",
        "ckpt_path = \"\" # @param {type:\"string\"}\n",
        "ckpt_folder = os.path.dirname(ckpt_path)\n",
        "ckpt_config = ckpt_folder + \"/config.yaml\"\n",
        "\n",
        "#@markdown your vocoder onnx save path\n",
        "export_path = \"\" # @param {type:\"string\"}\n",
        "save_path =  export_path + \"/model.ckpt\"\n",
        "\n",
        "#@markdown your vocoder name\n",
        "name = \"\" # @param {type:\"string\"}\n",
        "aaa2x = torch.load(ckpt_path)['state_dict']\n",
        "ckp = {}\n",
        "for i in aaa2x:\n",
        "    i: str\n",
        "    if 'generator.' in i:\n",
        "        ckp[i.replace('generator.', '')] = aaa2x[i]\n",
        "torch.save({'generator': ckp}, save_path)\n",
        "\n",
        "# copied from openvpi's vocoder\n",
        "config_data = {\n",
        "    \"resblock\": \"1\",\n",
        "    \"num_gpus\": 4,\n",
        "    \"batch_size\": 10,\n",
        "    \"learning_rate\": 0.0002,\n",
        "    \"adam_b1\": 0.8,\n",
        "    \"adam_b2\": 0.99,\n",
        "    \"lr_decay\": 0.999,\n",
        "    \"seed\": 1234,\n",
        "    \"upsample_rates\": [8, 8, 2, 2, 2],\n",
        "    \"upsample_kernel_sizes\": [16, 16, 4, 4, 4],\n",
        "    \"upsample_initial_channel\": 512,\n",
        "    \"resblock_kernel_sizes\": [3, 7, 11],\n",
        "    \"resblock_dilation_sizes\": [[1, 3, 5], [1, 3, 5], [1, 3, 5]],\n",
        "    \"discriminator_periods\": [3, 5, 7, 11, 17, 23, 37],\n",
        "    \"segment_size\": 16384,\n",
        "    \"num_mels\": 128,\n",
        "    \"num_freq\": 1025,\n",
        "    \"n_fft\": 2048,\n",
        "    \"hop_size\": 512,\n",
        "    \"win_size\": 2048,\n",
        "    \"sampling_rate\": 44100,\n",
        "    \"fmin\": 40,\n",
        "    \"fmax\": 16000,\n",
        "    \"fmax_for_loss\": None,\n",
        "    \"num_workers\": 16,\n",
        "    \"dist_config\": {\n",
        "        \"dist_backend\": \"nccl\",\n",
        "        \"dist_url\": \"tcp://localhost:54321\",\n",
        "        \"world_size\": 1\n",
        "    }\n",
        "}\n",
        "with open(f\"{export_path}/config.json\", \"w\") as json_file:\n",
        "    json.dump(config_data, json_file, indent=4)\n",
        "\n",
        "with open(ckpt_config, \"r\") as config:\n",
        "    add_vocoder_ckpt = yaml.safe_load(config)\n",
        "add_vocoder_ckpt[\"vocoder_ckpt\"] = save_path\n",
        "with open(ckpt_config, \"w\") as config:\n",
        "    yaml.dump(add_vocoder_ckpt, config)\n",
        "\n",
        "!cp {ckpt_config} {export_path}\n",
        "\n",
        "!python /content/DiffSinger/scripts/export.py nsf-hifigan --config {export_path}/config.yaml --out {export_path} --name {name}"
      ],
      "metadata": {
        "id": "NSoKhd7eE0Wq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}